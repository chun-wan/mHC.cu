# mHC.cu Fused Operators Optimization Results

**Test Environment**: Container 63015cccf5f7, 8x AMD MI308X, PyTorch 2.9.1+rocm7.2.0

## Individual Operator Fusion Results

### Stream Aggregation + RMSNorm Fusion

| Input Size | Non-fused | JIT Fused | **Speedup** |
|------------|-----------|-----------|-------------|
| (256, 4, 1280) | 0.300ms | 0.066ms | **4.55x** |
| (512, 4, 1920) | 0.756ms | 0.149ms | **5.07x** |
| (1024, 4, 2560) | 1.862ms | 0.363ms | **5.13x** |

### Sinkhorn-Knopp Fusion

| Matrix Size | Non-fused | JIT Fused | Speedup |
|-------------|-----------|-----------|---------|
| n=4 | 0.110ms | 0.077ms | 1.44x |
| n=8 | 0.110ms | 0.080ms | 1.37x |
| n=16 | 0.111ms | 0.105ms | 1.06x |

## Full mHC Layer Fusion Results

### Performance Comparison by Version

| Config | Non-fused | JIT Fused | **SuperFused** | AITER+Fused |
|--------|-----------|-----------|----------------|-------------|
| B=128, n=4, C=1280 | 0.534ms | 0.304ms | **0.241ms** | 0.317ms |
| B=256, n=4, C=1280 | 0.443ms | 0.305ms | **0.245ms** | 0.313ms |
| B=320, n=4, C=1280 | 0.522ms | 0.352ms | **0.267ms** | 0.341ms |
| B=512, n=4, C=1920 | 1.017ms | 0.738ms | **0.384ms** | 0.718ms |
| B=512, n=4, C=2560 | 1.310ms | 0.942ms | **0.472ms** | 0.911ms |
| B=1024, n=4, C=1920 | 1.872ms | 1.389ms | **0.694ms** | 1.349ms |

### Speedup Comparison

| Config | JIT Fused | **SuperFused** | AITER+Fused |
|--------|-----------|----------------|-------------|
| B=128, n=4, C=1280 | 1.76x | **2.21x** | 1.68x |
| B=256, n=4, C=1280 | 1.45x | **1.81x** | 1.41x |
| B=320, n=4, C=1280 | 1.48x | **1.96x** | 1.53x |
| B=512, n=4, C=1920 | 1.38x | **2.65x** | 1.42x |
| B=512, n=4, C=2560 | 1.39x | **2.77x** | 1.44x |
| B=1024, n=4, C=1920 | 1.35x | **2.70x** | 1.39x |

## Summary

### Average Speedup

| Method | Average Speedup |
|--------|-----------------|
| JIT Fused | 1.47x |
| AITER+Fused | 1.48x |
| **SuperFused** | **2.35x** |

### Best Configuration: SuperFused

**Reasons:**
1. Entire forward pass in a single JIT-compiled function
2. Minimizes Python call overhead
3. Compiler can optimize across operations
4. Reduces intermediate tensor memory allocations

### Correctness Verification

All fused versions have max difference within bf16 precision range (< 3e-02).

## Implementation Details

### SuperFused Core Code

```python
@torch.jit.script
def mhc_forward_superfused(
    x: torch.Tensor,
    H_pre: torch.Tensor,
    H_post: torch.Tensor,
    H_res: torch.Tensor,
    rmsnorm_weight: torch.Tensor,
    sinkhorn_iters: int,
    eps: float
) -> torch.Tensor:
    B, n, C = x.shape
    x_f32 = x.float()
    
    # Fused Block 1: Aggregation + RMSNorm
    H_pre_act = torch.sigmoid(H_pre)
    x_t = x_f32.transpose(1, 2)
    x_agg = torch.matmul(x_t, H_pre_act.unsqueeze(-1)).squeeze(-1)
    rms = torch.sqrt((x_agg ** 2).mean(dim=-1, keepdim=True) + eps)
    y_norm = (x_agg / rms) * rmsnorm_weight.float()
    
    # Fused Block 2: Sinkhorn-Knopp
    P = torch.exp(H_res)
    for _ in range(sinkhorn_iters):
        P = P / (P.sum(dim=-1, keepdim=True) + eps)
        P = P / (P.sum(dim=-2, keepdim=True) + eps)
    
    # Fused Block 3: Distribution + Mix + Add
    H_post_act = 2.0 * torch.sigmoid(H_post)
    mixed = torch.bmm(P.unsqueeze(0).expand(B, -1, -1), x_f32)
    output = mixed + H_post_act.view(1, n, 1) * y_norm.unsqueeze(1)
    
    return output
```

### Optimization Techniques

1. **einsum â†’ matmul/bmm**: Use direct matrix operations
2. **Single JIT function**: Reduce Python overhead
3. **In-place operations**: Reduce memory allocations
4. **Batch matrix multiply**: bmm is more efficient than einsum

## Conclusion

| Optimization Method | Forward Speedup | Recommendation |
|---------------------|-----------------|----------------|
| Non-fused baseline | 1.0x | - |
| AITER RMSNorm | 1.03x | Limited RMSNorm improvement |
| JIT Fused | 1.47x | Moderate improvement |
| **SuperFused** | **2.35x** | **Best choice** |

**Final Conclusion**: SuperFused fusion provides **2.35x** average speedup, making it the optimal choice.
